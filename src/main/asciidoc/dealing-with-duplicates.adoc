= Dealing with duplicates

Duplicated files are addressed by Fim in two different ways.

== Duplicates inside a Fim repository

Fim allow you to detect duplicates using the `fdup` command. It displays the list of duplicated files. +
See it in action in <<simple-example.adoc#_search_for_duplicated_files,Search for duplicated files>>.

If you want to remove them, Fim won't do it. It does not provide a smart way to remove those duplicates.

== Duplicates that are outside

You can use Fim to remove duplicated files that are located outside a Fim repository using the `rdup` command.
It can be useful if you want to cleanup old backups that are no more synchronized and you want to be sure to not lose any files that could have been modified or added.

=== Simple example

==== Create a source directory with some files in it

[source, bash]
------
$ cd /tmp
/tmp$ mkdir source
/tmp$ cd source/
/tmp/source$ for i in 01 02 03 04 05 06 07 08 09 10 ; do echo "New File $i" > file$i ; done
/tmp/source$ ll
total 48K
drwxrwxr-x  2 evrignaud evrignaud 4,0K mai   21 08:31 .
drwxrwxrwt 17 root      root      4,0K mai   21 08:31 ..
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file01
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file02
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file03
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file04
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file05
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file06
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file07
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file08
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file09
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file10
------

==== Initialize the Fim repository

[source, bash]
------
/tmp/source$ fim init -y
No comment provided. You are going to initialize your repository using the default comment.
2016/05/21 08:32:07 - Info  - Scanning recursively local files, using 'full' mode and 4 threads
(Hash progress legend for files grouped 10 by 10: # > 1 GB, @ > 200 MB, O > 100 MB, 8 > 50 MB, o > 20 MB, . otherwise)
.
2016/05/21 08:32:07 - Info  - Scanned 10 files (120 bytes), hashed 120 bytes (avg 120 bytes/s), during 00:00:00

Added:            file01
Added:            file02
Added:            file03
Added:            file04
Added:            file05
Added:            file06
Added:            file07
Added:            file08
Added:            file09
Added:            file10

10 added
------

==== Create a backup of this directory

[source, bash]
------
/tmp/source$ cd ..
/tmp$ cp -a source backup
------

==== Modify two files into the source directory and move two others

[source, bash]
------
/tmp$ cd source/
/tmp/source$ ll
total 52K
drwxrwxr-x  3 evrignaud evrignaud 4,0K mai   21 08:32 .
drwxrwxrwt 18 root      root      4,0K mai   21 08:32 ..
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file01
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file02
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file03
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file04
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file05
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file06
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file07
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file08
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file09
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file10
drwxrwxr-x  3 evrignaud evrignaud 4,0K mai   21 08:32 .fim
/tmp/source$ echo modif1 >> file02
/tmp/source$ echo modif2 >> file04
/tmp/source$ ll
total 52K
drwxrwxr-x  3 evrignaud evrignaud 4,0K mai   21 08:32 .
drwxrwxrwt 18 root      root      4,0K mai   21 08:32 ..
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file01
-rw-rw-r--  1 evrignaud evrignaud   19 mai   21 08:32 file02
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file03
-rw-rw-r--  1 evrignaud evrignaud   19 mai   21 08:32 file04
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file05
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file06
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file07
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file08
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file09
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file10
drwxrwxr-x  3 evrignaud evrignaud 4,0K mai   21 08:32 .fim
/tmp/source$ fim diff -s
2016/05/21 08:32:58 - Info  - Scanning recursively local files, using 'super-fast' mode and 4 threads
(Hash progress legend for files grouped 10 by 10: # > 1 GB, @ > 200 MB, O > 100 MB, 8 > 50 MB, o > 20 MB, . otherwise)
.
2016/05/21 08:32:58 - Info  - Scanned 10 files (134 bytes), hashed 134 bytes (avg 134 bytes/s), during 00:00:00

Comparing with the last committed state from 2016/05/21 08:32:07
Comment: Initial State

Content modified: file02 	creationTime: 2016/05/21 08:31:53 -> 2016/05/21 08:32:45
                         	lastModified: 2016/05/21 08:31:53 -> 2016/05/21 08:32:45

Content modified: file04 	creationTime: 2016/05/21 08:31:53 -> 2016/05/21 08:32:51
                         	lastModified: 2016/05/21 08:31:53 -> 2016/05/21 08:32:51


2 content modified
------

==== Commit all the modifications

[source, bash]
------
/tmp/source$ fim ci -s -c "Modifications"
2016/05/21 08:33:18 - Info  - Scanning recursively local files, using 'super-fast' mode and 4 threads
(Hash progress legend for files grouped 10 by 10: # > 1 GB, @ > 200 MB, O > 100 MB, 8 > 50 MB, o > 20 MB, . otherwise)
.
2016/05/21 08:33:18 - Info  - Scanned 10 files (134 bytes), hashed 134 bytes (avg 134 bytes/s), during 00:00:00

Comparing with the last committed state from 2016/05/21 08:32:07
Comment: Initial State

Content modified: file02 	creationTime: 2016/05/21 08:31:53 -> 2016/05/21 08:32:45
                         	lastModified: 2016/05/21 08:31:53 -> 2016/05/21 08:32:45

Content modified: file04 	creationTime: 2016/05/21 08:31:53 -> 2016/05/21 08:32:51
                         	lastModified: 2016/05/21 08:31:53 -> 2016/05/21 08:32:51


2 content modified

Do you really want to commit (y/n/A)? y
2016/05/21 08:33:20 - Info  - Retrieving the missing hash for all the modified files, using 'full' mode and 4 threads
2016/05/21 08:33:20 - Info  - Scanned 2 files (38 bytes), hashed 38 bytes (avg 38 bytes/s), during 00:00:00
------

==== Remove the duplicates

[source, bash]
------
/tmp/source$ cd ../backup/
/tmp/backup$ fim rdup -m ../source
2016/05/21 08:33:45 - Info  - Searching for duplicated files using the ../source directory as master

2016/05/21 08:33:45 - Info  - Scanning recursively local files, using 'full' mode and 4 threads
(Hash progress legend for files grouped 10 by 10: # > 1 GB, @ > 200 MB, O > 100 MB, 8 > 50 MB, o > 20 MB, . otherwise)
.
2016/05/21 08:33:46 - Info  - Scanned 10 files (120 bytes), hashed 120 bytes (avg 120 bytes/s), during 00:00:00

'file01' is a duplicate of '../source/file01'
Do you really want to remove it (y/n/A)? y
  'file01' removed
'file03' is a duplicate of '../source/file03'
Do you really want to remove it (y/n/A)? y
  'file03' removed
'file05' is a duplicate of '../source/file05'
Do you really want to remove it (y/n/A)? y
  'file05' removed
'file06' is a duplicate of '../source/file06'
Do you really want to remove it (y/n/A)? y
  'file06' removed
'file07' is a duplicate of '../source/file07'
Do you really want to remove it (y/n/A)? y
  'file07' removed
'file08' is a duplicate of '../source/file08'
Do you really want to remove it (y/n/A)? y
  'file08' removed
'file09' is a duplicate of '../source/file09'
Do you really want to remove it (y/n/A)? y
  'file09' removed
'file10' is a duplicate of '../source/file10'
Do you really want to remove it (y/n/A)? y
  'file10' removed

8 duplicated files found. 8 duplicated files removed
------

==== Only two different files remains

[source, bash]
------
/tmp/backup$ ll
total 20K
drwxrwxr-x  3 evrignaud evrignaud 4,0K mai   21 08:33 .
drwxrwxrwt 18 root      root      4,0K mai   21 08:33 ..
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file02
-rw-rw-r--  1 evrignaud evrignaud   12 mai   21 08:31 file04
drwxrwxr-x  3 evrignaud evrignaud 4,0K mai   21 08:32 .fim
------

==== Complex cases

Let say that you have:

* a directory with a big file tree that we will call the source location.
* other locations that contains some files that was copied long ago from this source location. We will call one those locations the backup location.

Now you want to cleanup the backup location from the files that are identical with the ones in the source location.
To find duplicates into the backup location we will use the hash located into the source `.fim` directory.
We will call master location the name of the directory where is this `.fim`. +
**Most of the time the master location is the source location.** +
If the source location is not reachable from the backup location, you just need to put a copy of the source `.fim` directory near the backup location.

[NOTE]
====
The backup location can contain also his own `.fim` directory. It will be ignored.
====

===== Step by step

* Go into the source location and ensure that all the hash are up to date:

[source, bash]
----
$ cd <source location>
$ fim ci -y -c "Content added"
----

* If the backup location cannot reach the source location (so master location is not the source location),
copy the `.fim` directory that is in the source location into a place near the backup location.

[source, bash]
----
$ cd <somewhere>
$ mkdir <master location>
$ scp -rp <remote host>@<source location>/.fim <master location>
----

[IMPORTANT]
====
The source `.fim` directory can't be nested into the root folder of the backup location.
====

* Run the remove duplicates command. For this, go in the backup location.

[source, bash]
----
$ cd <backup location>
$ fim rdup -m <master location>
----

